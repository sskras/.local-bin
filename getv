#! /usr/bin/env sh

# SPDX-License-Identifier: BlueOak-1.0.0
# SPDX-FileCopyrightText: 2025 Saulius Krasuckas <saulius2_at_ar-fi_point_lt> | sskras

# Get videos from the internet.

# 0. Fail early:
set -e

# List scheduled recordings by default:
if [ "$1" = "" ]; then
    atq -o %F\ %T | sort -Vk 2,3
    exit
fi

# List job details if the 1st argument is potentially a numeric ID (of the job):
if expr "$1" : "^[0-9]\+$" >/dev/null; then
    at -c $1 | awk '

        # Shell cmd in our at-jobs stats with sole opening parenthesis per line:

        $0 == "(" \
        {
            Cmd_started = 1
        }

        # Skip the head and the tail both preceding and following our cmd:

        ! Cmd_started || /^$/ \
        {
            next
        }

        # Display the actual cmd:

        {
            print
        }
        '
    exit
fi

# Record using default setting if the only argument is `.`:
if [ "$*" = "." ]; then
    set -- ""
fi
     Channel=${1:-lrt}
  Start_time=${2:-now}
    Duration=${3:-60m}

[ $# -le 3 ] && Done_args=$# || Done_args=3
shift ${Done_args}

# TODO: Unhardcode the 5 -- length of the `.part` appended by yt-dlp to the output fnames temporarily.
# TODO: Unhardcode the FS imposed limit:
 Fname_limit=$(( 255 - 5 ))

   Rhash_log="rhash-cummulative.log"

     #Tracks="hls-audio1-ORG+hls-audio1-LIT+hls-3"
      Tracks="audio1-ORG+audio1-LIT+5068"
 LRT2_Tracks="audio1-ORG+audio1-LIT+5365"
Audio_tracks="audio1-ORG+audio1-LIT"
  Start_date=$(date --date "${Start_time}" +%Y-%m-%d)
  Start_time=$(date --date "${Start_time}" +%H:%M)
        Name=${*:-[YEAR] ORIG (ENG; LITH)}
        Name=$(echo ${Name} | tr ' ' '-')
 Chan_suffix=$(echo ${Channel} | tr '[:lower:]' '[:upper:]')

gen_fnames ()
{
    Ext_name=${Name}-FHD\ ${Start_date}\ ${Start_time}
    Ext_name=$(echo ${Ext_name} | tr '/:' '_')

    # 2025-07-11 sskras: Generate custom output fnames;
    # (since the default ones broke)

      Output=${Ext_name}\ ${Chan_suffix}'.%(ext)s'
Audio_output=${Ext_name}\ Au'.%(ext)s'

    # Make sure the suffix (currently 'Au') is not longer than ${Chan_suffix}
    # in ${Audio_log}, so ${Log} is always the max length of the two:

         Log=${Ext_name}\ ${Chan_suffix}.log
   Audio_log=${Ext_name}\ Au.log

    # File to store the name (just in case it's too long):

Name_storage=${Ext_name}\ ${Chan_suffix}.txt

    # Name of the checksum file + its' length:

    Cheksums=${Ext_name}\ ${Chan_suffix}.sha1
Cheksums_len=${#Cheksums}
}

gen_fnames

if [ "${Cheksums_len}" -gt "${Fname_limit}" ]; then
    echo
    echo "Longest generated file name exceeds the calculated limit of ${Fname_limit} chars:"
    echo
    echo "    ${Cheksums}"
    echo
    echo "Its' length is ${Cheksums_len}. Fixing:"

    Original_name=${Name}

    # UTF-8 Ellipsis symbol occupies 3 additional bytes:
    Chars_to_truncate=$(( ${Cheksums_len} - ${Fname_limit} + 3 ))
    Ellipsis_UTF8='\u2026'
    # Via: https://stackoverflow.com/questions/27652458/whats-the-best-way-to-embed-a-unicode-character-in-a-posix-shell-script/27658989#27658989

    New_len=$(( ${#Name} - ${Chars_to_truncate} ))
    Name=$(env printf '%.*s'${Ellipsis_UTF8} ${New_len} "${Name}" | iconv -c)
    # Via: https://stackoverflow.com/questions/63430979/how-can-i-truncate-a-line-of-text-longer-than-a-given-length/63431166#63431166
    # Via: https://stackoverflow.com/questions/18700455/string-trimming-using-linux-cut-respecting-utf8-bondaries/18719951#18719951

    gen_fnames

    echo
    echo "    ${Output} "      " (${#Output} chars)"
    echo "    ${Audio_output}" " (${#Audio_output} chars)"
    echo "    ${Log} "         " (${#Log} chars)"
    echo "    ${Audio_log} "   " (${#Audio_log} chars)"

    echo
    echo "Stored the orignal name:"
    echo
    echo "    ${Original_name}"
    echo
fi

# Get the actual duration:

if ! expr "${Duration}" : " *[0-9]\+m *" >/dev/null; then
    Starting_secs=$(date -d "${Start_time}" +%s)
    Finishing_secs=$(date -d "${Duration}" +%s)

    if [ $Finishing_secs -lt $Starting_secs ]; then
        Finishing_secs=$(date -d "${Duration} ${Starting_date} tomorrow" +%s)
    fi
    Duration=$(( ($Finishing_secs - $Starting_secs) / 60 ))m
fi

Fn_lib='
resolve_the_playlist ()
{
    # For LRT, extract dynamic/tokenized playlist
    # URL from the playlist residing at fixed URL:
    curl -s $1 | jq -r .response.data.content
}
'
    # We start from the public streaming pages:
    #
    # LRT : "https://www.lrt.lt/mediateka/tiesiogiai/lrt-televizija"
    # LRT+: "https://www.lrt.lt/mediateka/tiesiogiai/lrt-plius"

    # Next, the static playlist URLs are extracted by hand:
    #
    # LRT : "https://www.lrt.lt/servisai/stream_url/live/get_live_url.php?channel=LTV1"
    # LRT+: "https://www.lrt.lt/servisai/stream_url/live/get_live_url.php?channel=LTV2"

    # Then the dynamic/tokenized/expiring URLs are extracted from the received JSON:
    #
    # LRT : "https://stream-syncwords.lrt.lt/out/v1/channel-group-lrt-portal-prod-01/channel-lrt-portal-prod-01/endpoint-lrt-portal-prod-01/index.m3u8?Expires=1752628991&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9zdHJlYW0tc3luY3dvcmRzLmxydC5sdC9vdXQvKiIsIkNvbmRpdGlvbiI6eyJJcEFkZHJlc3MiOiB7IkFXUzpTb3VyY2VJcCI6Ijc4LjU2LjIwMC4yMTUifSwiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTI2Mjg5OTF9fX1dfQ__&Signature=JlAfTuYXPOrao5ZTYVMXFc0~nRolI6wAw7FUmRkUHqfrv52hAOS6dR59P8yUSwrYrwFGwXhPPjTB24LkYi8HbTdbQglghsvs9cR1SyobhhfYOG9TBYef3Bn11O5V93fYLZ7yaLz8EYxnq6i9fp2aYER2Maq-YPZzRvYREpt9zfPkv~SnqJfcHoF0q7wLsKuyH-z5URnm5kcEo4juwAlpPM92r2mRlbbCg5t~G2t3CvVmgUtA4~WIwR3FPT4eSF-WMB8fUnT3xDZM0v5-w5x2vmMNvIbgSFgUn~6HC9OPJWCjmbMBzTVme4tr24n1P7ed26IQLXnHc6uY3AHCoRHHFA__&Key-Pair-Id=KAKLAV9ALHXL"
    # LRT+: "https://stream-secure.lrt.lt/plius/master.m3u8?Expires=1752267053&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9zdHJlYW0tc2VjdXJlLmxydC5sdC9wbGl1cy8qIiwiQ29uZGl0aW9uIjp7IklwQWRkcmVzcyI6IHsiQVdTOlNvdXJjZUlwIjoiODQuMTUuMTc4Ljc2In0sIkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzUyMjY3MDUzfX19XX0_&Signature=k5fU8WspD6kpCUQb9uKcd3sgIXzwxruChUVozF1m9NR6IShhNRMRU23AGcfmGWbFXxeV8IxVI7bIIf7Bt3McfEyGrW9vJDRa0JNeXGELbNB-VBzemn49W90zk~TIhzowHLuFr2KV6XnZqNv-QCnSx3XBPeUqvbazfkPTfI3cfV~W8OVTq3sGvXCQD690pna7cRZjSFF-cXMxVBvAyJT5XlTFRyR0IwHRmRVQoBKoZAfnOYt1osuxfJ8JWTf7R91mW09iUXPJJ9QZcW-Z6R0bkVtt92PZW8sYQSNUFbHBQ4frF8O7R3OeaxsKNPWVaXBYu1Sxr6vOZPUot9B6xa1FSg__&Key-Pair-Id=KAKLAV9ALHXL"

    # While the LRT version works fine with the key stripped,
    # ... the LRT+ version returns HTTP 403 without the key:
    #
    # <Code>MissingKey</Code><Message>Missing Key-Pair-Id query parameter or cookie value</Message>
    #
    # Seems like the dynamic key/cookie is used for sessions auth, which
    # restricts the stream's recipient both in time and per client's IP address.
    # Thus copying the URL to another machine does not work.

sched_dump ()
{
	if [ "$1" = "--audio-only" ]; then
	     Audio=1
	    Tracks=${Audio_tracks}
	    Output=${Audio_output}
	       Log=${Audio_log}
	fi
	cd
	at "${Start_time} ${Start_date}" <<- \
	---------------------------------------------------- 2>&1 |
	(
	    eval '${Fn_lib}'
	    date
	    pwd
	    Url=\$( resolve_the_playlist "${Url}" )
	    :
	    if [ -n "${Original_name}" ]; then
	        echo
	        echo "The untruncated name:"
	        echo
	        echo "${Original_name}"
	        echo
	    fi
	    :
	    timeout -s SIGINT                              \
	      --preserve-status                            \
	      ${Duration}                                  \
	      yt-dlp                                       \
	        --audio-multistreams                       \
	        -f "${Tracks}"                             \
	        -o "${Output}"                             \
	        "\${Url}"                                  \
	      ||
	    {
	        Capture_status=\$?
	        # Wait for yt-dlp / ffmpeg to finish:
	        sleep 4
	        echo
	        echo "Capture failed (\$Capture_status), cleaning up:"
	        rm -rv "${Ext_name}"*.part
	        exit
	    }
	    :
	    [ -n "${Audio}" ] && exit 0
	    :
	    if [ -n "${Original_name}" ]; then
	        echo
	        echo "${Original_name}" > "${Name_storage}"
	        echo
	    fi
	    :
	    # Launch another job to calculate checksums:
	    at now <<- \
		--------------------------------------------
	    (
	        # Wait for the audio batch, if any
	        sleep 10
	        # TODO: Improve sync ^
	        :
	        echo
	        echo "Calculating: ${Original_name}"
	        rhash --sha1 -P                        \
	          "${Ext_name}"*.mkv                   \
	          "${Ext_name}"*.log                   \
	          "${Ext_name}"*.txt                   \
	      | tee "${Cheksums}"
	        # Trailing NL and the log separator:
	        printf "\n%80s\n" | tr " " -
	    )                                          \
	    2>&1                                       \
	    | ts                                       \
	    >> "${Rhash_log}"
		--------------------------------------------
	    # Quit current job ASAP to close the log.
	) \
	> "${Log}" 2>&1
	----------------------------------------------------
	grep -v 'warning: commands will be executed using /bin/sh'
}

case $Channel in

  (lrt)
   #Url="https://www.lrt.lt/mediateka/tiesiogiai/lrt-televizija"
    # 2025-07-11: LRT streaming interface (Mediateka) got a maajor update,
    # and the old yt-dlp's playlist extractor for LRT broke.
    # Switch to the new, manually extracted URL:
   #Url="https://stream-syncwords.lrt.lt/out/v1/channel-group-lrt-portal-prod-01/channel-lrt-portal-prod-01/endpoint-lrt-portal-prod-01/index.m3u8"
    # 2025-07-15: Switch to the dynamic URL resolution (just as with LRT+ / LTV2);
    Url="https://www.lrt.lt/servisai/stream_url/live/get_live_url.php?channel=LTV1"

    sched_dump
    ;;

  (lrt+)
   #Url="https://www.lrt.lt/mediateka/tiesiogiai/lrt-plius"
    # 2025-07-11: Switch to the dynamic URL resolution;
    Url="https://www.lrt.lt/servisai/stream_url/live/get_live_url.php?channel=LTV2"
    Tracks="${LRT2_Tracks}"

    sched_dump
    # Also launch a secondary dump that would capture audio only.
    # It is to help in cases where full-featured capture gets its' audio lost.
    #
    # And this way (by having secondary, audio-only dump happenig in parallel),
    # it seems to help the full-featured capture to not lose the audio
    # (at least never in the several months long run).
    sched_dump --audio-only
    ;;

  (*)
    Url="TODO://unknown-channel"
    echo "Implement Url for '${Channel}' channel: ${Url}"
    exit 1
    ;;
esac


echo "Using some defaults:"

# TODO Via:
#
# $ diff -u <(at -c 727 | tail -3 | fmt -u) <(at -c 728 | tail -3 | fmt -u) | colordiff
# --- /dev/fd/63  2025-04-13 16:14:49.596014294 +0300
# +++ /dev/fd/62  2025-04-13 16:14:49.596014294 +0300
# @@ -1,5 +1,5 @@
#    timeout -s SIGINT 60m yt-dlp --audio-multistreams -f
# -  "hls-audio1-ORG+hls-audio1-LIT+hls-3" -o "%(title)s [%(id)s].%(ext)s"
# +  "hls-audio1-ORG+hls-audio1-LIT" -o "%(title)s [%(id)s]-audio.%(ext)s"
#    https://www.lrt.lt/mediateka/tiesiogiai/lrt-plius
# -) > "[YEAR]-ORIG-(ENG;-LITH)-16:12:16-FHD.2025-04-13-LRT+.log" 2>&1
# +) > "[YEAR]-ORIG-(ENG;-LITH)-16:12:16-FHD.2025-04-13-LRT+audio.log" 2>&1
# 
# vim: ts=4 sw=4 noet
